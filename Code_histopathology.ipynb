{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse with low rank-attention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import DropPath\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from timm import create_model\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "from thop import profile\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42  # You can choose any integer\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# If using CUDA, also set the seed for GPU\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)  # If using multi-GPU\n",
    "\n",
    "# Dataset transformations\n",
    "train_val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Dataset loading\n",
    "dataset_path = 'Kather_texture_2016_image_tiles_5000'\n",
    "dataset = datasets.ImageFolder(dataset_path)\n",
    "test_size = int(len(dataset) * 0.2)\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "val_size = int(train_size * 0.1)\n",
    "train_size = train_size - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = train_val_transform\n",
    "val_dataset.dataset.transform = train_val_transform\n",
    "test_dataset.dataset.transform = test_transform\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Teacher models (ViT, DeiT, Swin)\n",
    "teacher_vit = create_model('vit_base_patch16_224', pretrained=True, num_classes=len(dataset.classes)).cuda()\n",
    "teacher_deit = create_model('deit_base_patch16_224', pretrained=True, num_classes=len(dataset.classes)).cuda()\n",
    "teacher_swin = create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=len(dataset.classes)).cuda()\n",
    "\n",
    "# Low-Rank Sparse Multi-Head Attention\n",
    "class LowRankSparseMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, rank, sparsity_ratio=0.5):\n",
    "        super(LowRankSparseMultiheadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.rank = rank\n",
    "        self.sparsity_ratio = sparsity_ratio\n",
    "        \n",
    "        # Independent low-rank projections for each head, using full embed_dim\n",
    "        self.q_lows = nn.ModuleList([nn.Linear(embed_dim, rank, bias=False) for _ in range(num_heads)])\n",
    "        self.q_highs = nn.ModuleList([nn.Linear(rank, embed_dim, bias=False) for _ in range(num_heads)])\n",
    "        \n",
    "        self.k_lows = nn.ModuleList([nn.Linear(embed_dim, rank, bias=False) for _ in range(num_heads)])\n",
    "        self.k_highs = nn.ModuleList([nn.Linear(rank, embed_dim, bias=False) for _ in range(num_heads)])\n",
    "        \n",
    "        self.v_lows = nn.ModuleList([nn.Linear(embed_dim, rank, bias=False) for _ in range(num_heads)])\n",
    "        self.v_highs = nn.ModuleList([nn.Linear(rank, embed_dim, bias=False) for _ in range(num_heads)])\n",
    "        \n",
    "        self.out_proj = nn.Linear(embed_dim * num_heads, embed_dim)\n",
    "        self.scale = embed_dim ** -0.5\n",
    "\n",
    "    def sparse_attention(self, attn_scores, sparsity_ratio):\n",
    "        \"\"\"Apply sparsity to the attention scores by masking out low-ranked elements.\"\"\"\n",
    "        batch_size, num_heads, seq_length, _ = attn_scores.size()\n",
    "\n",
    "        if seq_length == 1:\n",
    "            return attn_scores  # Dense attention if sequence length is 1\n",
    "\n",
    "        num_to_keep = int(sparsity_ratio * seq_length)\n",
    "        top_scores, _ = torch.topk(attn_scores, k=num_to_keep, dim=-1)\n",
    "        threshold = top_scores.min(dim=-1, keepdim=True)[0]\n",
    "        sparse_mask = attn_scores >= threshold\n",
    "        return attn_scores * sparse_mask.float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "\n",
    "        q, k, v = [], [], []\n",
    "        for i in range(self.num_heads):\n",
    "            # Use full embed_dim for each head\n",
    "            q_head = self.q_highs[i](self.q_lows[i](x)).view(batch_size, seq_length, embed_dim)\n",
    "            k_head = self.k_highs[i](self.k_lows[i](x)).view(batch_size, seq_length, embed_dim)\n",
    "            v_head = self.v_highs[i](self.v_lows[i](x)).view(batch_size, seq_length, embed_dim)\n",
    "            q.append(q_head)\n",
    "            k.append(k_head)\n",
    "            v.append(v_head)\n",
    "\n",
    "        q = torch.stack(q, dim=1)  # (batch_size, num_heads, seq_length, embed_dim)\n",
    "        k = torch.stack(k, dim=1)\n",
    "        v = torch.stack(v, dim=1)\n",
    "\n",
    "        # Scaled dot-product attention per head\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        # Apply sparse attention\n",
    "        sparse_attn_scores = self.sparse_attention(attn_scores, self.sparsity_ratio)\n",
    "\n",
    "        attn_probs = F.softmax(sparse_attn_scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_probs, v)\n",
    "\n",
    "        # Concatenate output from all heads along the embedding dimension\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_length, self.num_heads * embed_dim)\n",
    "\n",
    "        # Final projection\n",
    "        output = self.out_proj(attn_output)\n",
    "        return output\n",
    "    \n",
    "# Custom DeiT Layer using Low-Rank Sparse Attention\n",
    "class CustomDeiTLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, rank, mlp_ratio=4., drop_path=0.1, sparsity_ratio=0.5):\n",
    "        super(CustomDeiTLayer, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = LowRankSparseMultiheadAttention(embed_dim, num_heads, rank, sparsity_ratio)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_hidden_dim, embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply low-rank sparse multi-head attention\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "# Hybrid Student Model\n",
    "class HybridStudentModel(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim=768, num_heads=8, num_layers=2, rank=32, drop_path_rate=0.95, sparsity_ratio=0.9):\n",
    "        super(HybridStudentModel, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # Custom DeiT layers with low-rank sparse attention\n",
    "        self.deit_layers = nn.ModuleList([\n",
    "            CustomDeiTLayer(embed_dim, num_heads, rank, drop_path=drop_path_rate, sparsity_ratio=sparsity_ratio) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.deit_embed = nn.Linear(2000, embed_dim)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        resnet_feats = self.resnet(x)\n",
    "        densenet_feats = self.densenet(x)\n",
    "        combined_feats = torch.cat((resnet_feats, densenet_feats), dim=1)\n",
    "        combined_feats = combined_feats.view(combined_feats.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Add sequence dimension (seq_length=1)\n",
    "        combined_feats = combined_feats.unsqueeze(1)\n",
    "        \n",
    "        # Embedding and Transformer block\n",
    "        x = self.deit_embed(combined_feats)\n",
    "        for layer in self.deit_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        x = x.squeeze(1)  # Remove sequence dimension\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Distillation Loss\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=3.0):\n",
    "        super(DistillationLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.kl_div = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, ground_truth):\n",
    "        hard_loss = self.ce_loss(student_logits, ground_truth)\n",
    "        soft_loss = self.kl_div(\n",
    "            F.log_softmax(student_logits / self.temperature, dim=1),\n",
    "            F.softmax(teacher_logits / self.temperature, dim=1)\n",
    "        ) * (self.temperature ** 2)\n",
    "        return self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
    "\n",
    "# Evaluate Model\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    correct, total, test_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = test_loss / len(data_loader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Train Model with Distillation\n",
    "def train_model_with_distillation(student_model, teacher_models, train_loader, val_loader, distillation_criterion, optimizer, num_epochs=20):\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        student_model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student_model(images)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = [teacher(images) for teacher in teacher_models]\n",
    "                combined_teacher_logits = sum(teacher_logits) / len(teacher_logits)\n",
    "            loss = distillation_criterion(student_outputs, combined_teacher_logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy, _ = evaluate_model(student_model, train_loader, distillation_criterion.ce_loss)\n",
    "        val_accuracy, val_loss = evaluate_model(student_model, val_loader, distillation_criterion.ce_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "              f'Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%')\n",
    "    return student_model, train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# Instantiate and train the model\n",
    "num_classes = len(dataset.classes)\n",
    "hybrid_model = HybridStudentModel(num_classes).cuda()\n",
    "criterion = DistillationLoss(alpha=0.5, temperature=3.0)\n",
    "optimizer = optim.SGD(hybrid_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "teacher_models = [teacher_vit, teacher_deit, teacher_swin]\n",
    "\n",
    "# Train the student model\n",
    "trained_model, train_losses, val_losses, train_accuracies, val_accuracies = train_model_with_distillation(\n",
    "    hybrid_model, teacher_models, train_loader, val_loader, criterion, optimizer, num_epochs=3\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy, test_loss = evaluate_model(trained_model, test_loader, criterion.ce_loss)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Function to count the number of parameters in a model\n",
    "def count_custom_parameters(model, exclude_list=None):\n",
    "    \"\"\"\n",
    "    Count the number of trainable parameters excluding those from specified submodules.\n",
    "\n",
    "    \"\"\"\n",
    "    exclude_list = exclude_list or []\n",
    "    excluded_params = set(p for submodule in exclude_list for p in submodule.parameters())\n",
    "\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad and p not in excluded_params)\n",
    "\n",
    "# Instantiate the model\n",
    "hybrid_model = HybridStudentModel(num_classes).cuda()\n",
    "\n",
    "# Exclude the ResNet and DenseNet parameters\n",
    "excluded_models = [hybrid_model.resnet, hybrid_model.densenet]\n",
    "\n",
    "# Count parameters in custom layers only\n",
    "custom_params = count_custom_parameters(hybrid_model, exclude_list=excluded_models)\n",
    "print(f'Number of trainable parameters in custom layers: {custom_params}')\n",
    "\n",
    "# Create a dummy input for FLOP calculation\n",
    "dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n",
    "# Calculate FLOPs using thop\n",
    "flops, params = profile(hybrid_model, inputs=(dummy_input,))\n",
    "print(f'Number of FLOPs in the hybrid model: {flops:.2e}')\n",
    "\n",
    "# Convert FLOPs to GHz\n",
    "flops_per_cycle = 8 * 10**9  # 8 FLOPs per clock cycle for a GHz processor\n",
    "required_ghz = flops / flops_per_cycle\n",
    "print(f'Approximate GHz required: {required_ghz:.4f} GHz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc005f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple multihead attention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import DropPath\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from timm import create_model\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "from thop import profile\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42  # You can choose any integer\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# If using CUDA, also set the seed for GPU\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)  # If using multi-GPU\n",
    "\n",
    "# Dataset transformations\n",
    "train_val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Dataset loading\n",
    "dataset_path = 'Kather_texture_2016_image_tiles_5000'\n",
    "dataset = datasets.ImageFolder(dataset_path)\n",
    "test_size = int(len(dataset) * 0.2)\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "val_size = int(train_size * 0.1)\n",
    "train_size = train_size - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = train_val_transform\n",
    "val_dataset.dataset.transform = train_val_transform\n",
    "test_dataset.dataset.transform = test_transform\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Teacher models (ViT, DeiT, Swin)\n",
    "teacher_vit = create_model('vit_base_patch16_224', pretrained=True, num_classes=len(dataset.classes)).cuda()\n",
    "teacher_deit = create_model('deit_base_patch16_224', pretrained=True, num_classes=len(dataset.classes)).cuda()\n",
    "teacher_swin = create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=len(dataset.classes)).cuda()\n",
    "\n",
    "# Low-Rank Sparse Multi-Head Attention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = embed_dim ** -0.5  # Scaling factor for attention\n",
    "\n",
    "        # Independent linear projections for each head (all using embed_dim, not divided)\n",
    "        self.q_proj_heads = nn.ModuleList([nn.Linear(embed_dim, embed_dim) for _ in range(num_heads)])\n",
    "        self.k_proj_heads = nn.ModuleList([nn.Linear(embed_dim, embed_dim) for _ in range(num_heads)])\n",
    "        self.v_proj_heads = nn.ModuleList([nn.Linear(embed_dim, embed_dim) for _ in range(num_heads)])\n",
    "\n",
    "        # Final output projection\n",
    "        self.out_proj = nn.Linear(embed_dim * num_heads, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "        \n",
    "\n",
    "        q, k, v = [], [], []\n",
    "        for i in range(self.num_heads):\n",
    "            # Use the full embed_dim for each head's query, key, and value projections\n",
    "            q_head = self.q_proj_heads[i](x).view(batch_size, seq_length, embed_dim)\n",
    "            k_head = self.k_proj_heads[i](x).view(batch_size, seq_length, embed_dim)\n",
    "            v_head = self.v_proj_heads[i](x).view(batch_size, seq_length, embed_dim)\n",
    "            q.append(q_head)\n",
    "            k.append(k_head)\n",
    "            v.append(v_head)\n",
    "\n",
    "        # Stack the queries, keys, and values across heads\n",
    "        q = torch.stack(q, dim=1)  # (batch_size, num_heads, seq_length, embed_dim)\n",
    "        k = torch.stack(k, dim=1)\n",
    "        v = torch.stack(v, dim=1)\n",
    "\n",
    "        # Scaled dot-product attention for each head\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        # Attention output for each head\n",
    "        attn_output = torch.matmul(attn_probs, v)\n",
    "\n",
    "        # Concatenate outputs from all heads and project to final output\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_length, self.num_heads * embed_dim)\n",
    "\n",
    "        output = self.out_proj(attn_output)\n",
    "        return output\n",
    "    \n",
    "# Custom DeiT Layer using Low-Rank Sparse Attention\n",
    "class CustomDeiTLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, rank, mlp_ratio=4., drop_path=0.1, sparsity_ratio=0.5):\n",
    "        super(CustomDeiTLayer, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = MultiheadAttention(embed_dim, num_heads)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_hidden_dim, embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply low-rank sparse multi-head attention\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "# Hybrid Student Model\n",
    "class HybridStudentModel(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim=768, num_heads=8, num_layers=2, rank=32, drop_path_rate=0.1, sparsity_ratio=0.5):\n",
    "        super(HybridStudentModel, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # Custom DeiT layers with low-rank sparse attention\n",
    "        self.deit_layers = nn.ModuleList([\n",
    "            CustomDeiTLayer(embed_dim, num_heads, rank, drop_path=drop_path_rate, sparsity_ratio=sparsity_ratio) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.deit_embed = nn.Linear(2000, embed_dim)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        resnet_feats = self.resnet(x)\n",
    "        densenet_feats = self.densenet(x)\n",
    "        combined_feats = torch.cat((resnet_feats, densenet_feats), dim=1)\n",
    "        combined_feats = combined_feats.view(combined_feats.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Add sequence dimension (seq_length=1)\n",
    "        combined_feats = combined_feats.unsqueeze(1)\n",
    "        \n",
    "        # Embedding and Transformer block\n",
    "        x = self.deit_embed(combined_feats)\n",
    "        for layer in self.deit_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        x = x.squeeze(1)  # Remove sequence dimension\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Distillation Loss\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=3.0):\n",
    "        super(DistillationLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.kl_div = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, ground_truth):\n",
    "        hard_loss = self.ce_loss(student_logits, ground_truth)\n",
    "        soft_loss = self.kl_div(\n",
    "            F.log_softmax(student_logits / self.temperature, dim=1),\n",
    "            F.softmax(teacher_logits / self.temperature, dim=1)\n",
    "        ) * (self.temperature ** 2)\n",
    "        return self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
    "\n",
    "# Evaluate Model\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    correct, total, test_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = test_loss / len(data_loader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Train Model with Distillation\n",
    "def train_model_with_distillation(student_model, teacher_models, train_loader, val_loader, distillation_criterion, optimizer, num_epochs=20):\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        student_model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student_model(images)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = [teacher(images) for teacher in teacher_models]\n",
    "                combined_teacher_logits = sum(teacher_logits) / len(teacher_logits)\n",
    "            loss = distillation_criterion(student_outputs, combined_teacher_logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy, _ = evaluate_model(student_model, train_loader, distillation_criterion.ce_loss)\n",
    "        val_accuracy, val_loss = evaluate_model(student_model, val_loader, distillation_criterion.ce_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "              f'Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%')\n",
    "    return student_model, train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# Instantiate and train the model\n",
    "num_classes = len(dataset.classes)\n",
    "hybrid_model = HybridStudentModel(num_classes).cuda()\n",
    "criterion = DistillationLoss(alpha=0.5, temperature=3.0)\n",
    "optimizer = optim.SGD(hybrid_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "teacher_models = [teacher_vit, teacher_deit, teacher_swin]\n",
    "\n",
    "# Train the student model\n",
    "trained_model, train_losses, val_losses, train_accuracies, val_accuracies = train_model_with_distillation(\n",
    "    hybrid_model, teacher_models, train_loader, val_loader, criterion, optimizer, num_epochs=2\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy, test_loss = evaluate_model(trained_model, test_loader, criterion.ce_loss)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Function to count the number of parameters in a model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print the number of parameters in the student model\n",
    "num_params = count_parameters(hybrid_model)\n",
    "print(f'Number of trainable parameters in the hybrid model: {num_params}')\n",
    "\n",
    "# Create a dummy input for FLOP calculation\n",
    "dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n",
    "# Calculate FLOPs using thop\n",
    "flops, params = profile(hybrid_model, inputs=(dummy_input,))\n",
    "print(f'Number of FLOPs in the hybrid model: {flops:.2e}')\n",
    "\n",
    "# Convert FLOPs to GHz\n",
    "flops_per_cycle = 8 * 10**9  # 8 FLOPs per clock cycle for a GHz processor\n",
    "required_ghz = flops / flops_per_cycle\n",
    "print(f'Approximate GHz required: {required_ghz:.4f} GHz')\n",
    "\n",
    "###########\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
